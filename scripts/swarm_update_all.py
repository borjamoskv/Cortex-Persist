#!/usr/bin/env python3
"""
SWARM_UPDATE_ALL ‚Äî Enjambre Masivo de Actualizaci√≥n
====================================================
Actualiza TODOS los assets del ecosistema MOSKV-1 con el patr√≥n
de enjambre masivo (LEGI√òN-1) y especialistas:
  - 37 SKILLs (.gemini/antigravity/skills/*/SKILL.md)
  - 119 Workflows (.agent/workflows/*.md)
  - 51 Scripts Python (.gemini/antigravity/skills/*/scripts/*.py)

Caracter√≠sticas:
  - Rate limiting inteligente (RPM + TPM)
  - Retry con backoff exponencial
  - Progreso en tiempo real
  - Backup autom√°tico antes de escribir
  - Modo --dry-run para previsualizar
  - Filtros por tipo (--skills, --workflows, --scripts)
  - Log de resultados al final
"""

import argparse
import glob
import shutil
import sys
import time
from datetime import datetime
from pathlib import Path

from dotenv import load_dotenv

load_dotenv()

try:
    from google import genai
    from google.genai import types
except ImportError:
    print("‚ùå google-genai no instalado. Ejecuta: pip install google-genai")
    sys.exit(1)

# ‚îÄ‚îÄ‚îÄ PATHS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SKILLS_DIR = Path.home() / ".gemini" / "antigravity" / "skills"
WORKFLOWS_DIR = Path.home() / "cortex" / ".agent" / "workflows"
BACKUP_DIR = Path.home() / ".cortex" / "swarm_backup" / datetime.now().strftime("%Y%m%d_%H%M%S")
LOG_FILE = Path.home() / ".cortex" / "swarm_update.log"

# ‚îÄ‚îÄ‚îÄ RATE LIMITS (gemini-2.5-flash free tier) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
RPM_LIMIT = 10  # requests per minute (conservative)
DELAY_BETWEEN = 6.5  # seconds between requests (60/RPM + buffer)
MAX_RETRIES = 4
BACKOFF_BASE = 2.0  # exponential backoff: 2, 4, 8, 16 seconds

# ‚îÄ‚îÄ‚îÄ PROMPTS POR TIPO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

SKILL_PROMPT = """Eres MOSKV-1 v5. Ejecuta `void-omega + legion-1` sobre este SKILL.md.

MISI√ìN: Inyectar el patr√≥n de ENJAMBRE MASIVO y ESPECIALISTAS donde tenga sentido.
No destruyas ‚Äî amplifica. Si el skill ya tiene swarm, refuerza.

REGLAS ESTRICTAS:
1. Mant√©n la estructura YAML frontmatter EXACTA (entre ---). No la modifiques.
2. Mant√©n todos los bloques de c√≥digo ```...``` EXACTOS, sin modificar.
3. A√±ade una secci√≥n `## üêù Especialistas del Enjambre` si no existe, con:
   - M√≠nimo 3 especialistas nombrados relevantes al dominio del skill
   - Su trigger de activaci√≥n y su misi√≥n espec√≠fica
4. A√±ade/refuerza referencias a formaciones LEGI√òN-1 (BLITZ, PHALANX, HYDRA, SIEGE) donde sea sem√°nticamente correcto.
5. Aplica "Zero Fluff": elimina relleno, met√°foras vac√≠as, frases sin acci√≥n.
6. Estilo: imperativo, denso, contundente. Filosof√≠a 130/100.
7. Responde SOLO con el Markdown procesado ‚Äî sin bloques delimitadores externos.
"""

WORKFLOW_PROMPT = """Eres MOSKV-1 v5. Actualiza este workflow con el patr√≥n de ENJAMBRE y ESPECIALISTAS.

MISI√ìN: Hacer que cada workflow active el especialista correcto autom√°ticamente.

REGLAS ESTRICTAS:
1. Mant√©n el YAML frontmatter (entre ---) EXACTO.
2. Mant√©n todos los bloques de c√≥digo EXACTOS.
3. A√±ade un bloque `### üêù Especialistas Activados` al inicio o donde proceda, listando:
   - Qu√© agente/modelo especialista se activa para este workflow
   - En qu√© condici√≥n se escala a enjambre (BLITZ/PHALANX)
4. A√±ade la anotaci√≥n `// turbo` sobre pasos que sean seguros de auto-ejecutar si no la tienen.
5. Zero Fluff: elimina pasos redundantes o explicaciones innecesarias.
6. Responde SOLO con el Markdown procesado ‚Äî sin bloques delimitadores externos.
"""

PYTHON_PROMPT = """Eres MOSKV-1 v5, Senior Python Architect. Actualiza este script Python \
para que soporte despacho a especialistas y enjambre LEGI√òN-1.

MISI√ìN: Si el script realiza operaciones que pueden paralelizarse, a√±ade soporte de enjambre.

REGLAS ESTRICTAS:
1. Mant√©n la funcionalidad EXACTA del script ‚Äî no rompas nada.
2. Si el script ya tiene asyncio/threading/multiprocessing, refuerza con patrones de enjambre.
3. A√±ade una funci√≥n `_dispatch_specialist(task, specialist_id)` si hay >3 operaciones \
   secuenciales que podr√≠an ser paralelas. Si no aplica, NO la a√±adas.
4. A√±ade/mejora el logging con timestamps y emojis de estado (‚úÖ ‚ùå ‚ö° üêù).
5. A√±ade type hints donde falten (solo en funciones existentes, no inventes nuevas).
6. Mant√©n el shebang y los imports existentes.
7. Zero Fluff: elimina comentarios obviamente redundantes.
8. Responde SOLO con el c√≥digo Python procesado ‚Äî sin bloques de c√≥digo ```python delimitadores.
"""

# ‚îÄ‚îÄ‚îÄ COLORES TERMINAL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GREEN = "\033[92m"
RED = "\033[91m"
YELLOW = "\033[93m"
CYAN = "\033[96m"
BOLD = "\033[1m"
RESET = "\033[0m"
DIM = "\033[2m"


def c(color: str, text: str) -> str:
    return f"{color}{text}{RESET}"


# ‚îÄ‚îÄ‚îÄ STATS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
stats = {"ok": 0, "skip": 0, "fail": 0, "total": 0}
failures: list[tuple[str, str]] = []

# ‚îÄ‚îÄ‚îÄ HELPERS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def backup_file(path: Path) -> None:
    """Crea backup antes de sobreescribir."""
    rel = path.relative_to(Path.home())
    dest = BACKUP_DIR / rel
    dest.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(path, dest)


def log(msg: str) -> None:
    LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now():%H:%M:%S}] {msg}\n")


def strip_outer_fences(text: str, lang: str = "") -> str:
    """Elimina bloques delimitadores si el LLM los a√±adi√≥."""
    text = text.strip()
    for prefix in (f"```{lang}", "```"):
        if text.startswith(prefix):
            text = text[len(prefix) :]
            break
    if text.endswith("```"):
        text = text[:-3]
    return text.strip()


def call_gemini(client, prompt: str, content: str, file_label: str) -> str | None:
    """Llama a Gemini con retry + backoff exponencial."""
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[
                    types.Part.from_text(text=prompt),
                    types.Part.from_text(text=content),
                ],
                config=types.GenerateContentConfig(
                    temperature=0.2,
                    max_output_tokens=8192,
                ),
            )
            return response.text
        except Exception as e:
            err_str = str(e).lower()
            wait = BACKOFF_BASE**attempt
            if "quota" in err_str or "429" in err_str or "resource_exhausted" in err_str:
                print(
                    c(
                        YELLOW,
                        f"  ‚è≥ Rate limit ({attempt}/{MAX_RETRIES}). Esperando {wait:.0f}s...",
                    )
                )
                time.sleep(wait)
            elif "503" in err_str or "capacity" in err_str:
                print(
                    c(
                        YELLOW,
                        f"  üåä Capacidad agotada ({attempt}/{MAX_RETRIES}). Esperando {wait:.0f}s...",
                    )
                )
                time.sleep(wait)
            else:
                print(c(RED, f"  ‚ùå Error en {file_label}: {e}"))
                log(f"ERROR {file_label}: {e}")
                return None
    return None


def split_frontmatter(content: str) -> tuple[str, str]:
    """Separa YAML frontmatter del body."""
    if content.startswith("---"):
        parts = content.split("---", 2)
        if len(parts) >= 3:
            return parts[1], parts[2]
    return "", content


def process_markdown(
    client,
    path: Path,
    prompt: str,
    file_type: str,
    dry_run: bool,
    index: int,
    total: int,
) -> bool:
    """Procesa un archivo markdown (SKILL o workflow)."""
    label = path.name
    prefix = c(CYAN, f"[{index:3d}/{total}]")
    print(f"{prefix} {c(BOLD, file_type)} {DIM}{path}{RESET}")

    content = path.read_text(encoding="utf-8", errors="ignore")
    frontmatter, body = split_frontmatter(content)

    result = call_gemini(client, prompt, body, str(path))
    if result is None:
        failures.append((str(path), "API call failed"))
        stats["fail"] += 1
        return False

    processed = strip_outer_fences(result, "markdown")

    # Reconstruir con frontmatter original
    new_content = f"---{frontmatter}---\n{processed}\n"

    if dry_run:
        print(c(YELLOW, f"  [DRY-RUN] Cambios detectados en {label}"))
        print(f"  Preview (100 chars): {processed[:100]}...")
        stats["ok"] += 1
        return True

    backup_file(path)
    path.write_text(new_content, encoding="utf-8")
    print(c(GREEN, "  ‚úÖ Actualizado"))
    log(f"OK {file_type} {path}")
    stats["ok"] += 1
    return True


def process_python(
    client,
    path: Path,
    dry_run: bool,
    index: int,
    total: int,
) -> bool:
    """Procesa un script Python."""
    prefix = c(CYAN, f"[{index:3d}/{total}]")
    print(f"{prefix} {c(BOLD, 'üêç PY')} {DIM}{path}{RESET}")

    content = path.read_text(encoding="utf-8", errors="ignore")

    # Skip archivos muy peque√±os (<50 l√≠neas) ‚Äî no hay suficiente contexto
    if content.count("\n") < 50:
        print(c(DIM, "  ‚è≠  Skip (< 50 l√≠neas)"))
        stats["skip"] += 1
        return True

    result = call_gemini(client, PYTHON_PROMPT, content, str(path))
    if result is None:
        failures.append((str(path), "API call failed"))
        stats["fail"] += 1
        return False

    processed = strip_outer_fences(result, "python")

    if dry_run:
        print(c(YELLOW, f"  [DRY-RUN] {path.name} procesado"))
        stats["ok"] += 1
        return True

    backup_file(path)
    path.write_text(processed + "\n", encoding="utf-8")
    print(c(GREEN, "  ‚úÖ Actualizado"))
    log(f"OK PY {path}")
    stats["ok"] += 1
    return True


# ‚îÄ‚îÄ‚îÄ COLLECTORS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def collect_skills() -> list[Path]:
    return sorted(SKILLS_DIR.glob("*/SKILL.md"))


def collect_workflows() -> list[Path]:
    if not WORKFLOWS_DIR.exists():
        print(c(YELLOW, f"‚ö†Ô∏è  Workflows dir no existe: {WORKFLOWS_DIR}"))
        return []
    return sorted(WORKFLOWS_DIR.glob("*.md"))


def collect_scripts() -> list[Path]:
    patterns = [
        str(SKILLS_DIR / "*" / "scripts" / "*.py"),
        str(SKILLS_DIR / "*" / "*.py"),
    ]
    paths = set()
    for pat in patterns:
        for p in glob.glob(pat):
            paths.add(Path(p))
    return sorted(paths)


# ‚îÄ‚îÄ‚îÄ MAIN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def main():
    parser = argparse.ArgumentParser(description="SWARM_UPDATE_ALL ‚Äî Enjambre Masivo MOSKV-1")
    parser.add_argument("--skills", action="store_true", help="Solo SKILLs")
    parser.add_argument("--workflows", action="store_true", help="Solo Workflows")
    parser.add_argument("--scripts", action="store_true", help="Solo Scripts Python")
    parser.add_argument("--dry-run", action="store_true", help="Previsualizar sin escribir")
    parser.add_argument("--limit", type=int, default=0, help="Max archivos a procesar (0=todos)")
    args = parser.parse_args()

    # Si no se especifica filtro, actualiza todo
    do_skills = args.skills or not (args.skills or args.workflows or args.scripts)
    do_workflows = args.workflows or not (args.skills or args.workflows or args.scripts)
    do_scripts = args.scripts or not (args.skills or args.workflows or args.scripts)

    client = genai.Client()

    # Recopilar targets
    targets: list[tuple[Path, str, str]] = []  # (path, prompt, type_label)

    if do_skills:
        for p in collect_skills():
            targets.append((p, SKILL_PROMPT, "üß¨ SKILL"))

    if do_workflows:
        for p in collect_workflows():
            targets.append((p, WORKFLOW_PROMPT, "‚ö° FLOW"))

    if do_scripts:
        for p in collect_scripts():
            targets.append((p, PYTHON_PROMPT, "üêç PY"))

    if args.limit > 0:
        targets = targets[: args.limit]

    total = len(targets)
    stats["total"] = total

    print(f"\n{c(BOLD, 'üêù SWARM_UPDATE_ALL ‚Äî Enjambre Masivo')}")
    print(f"   Targets: {c(BOLD, str(total))} archivos")
    print(f"   Backup:  {BACKUP_DIR}")
    print(f"   Mode:    {'DRY-RUN' if args.dry_run else 'LIVE'}")
    print(f"   Delay:   {DELAY_BETWEEN}s entre requests\n")

    if not args.dry_run:
        BACKUP_DIR.mkdir(parents=True, exist_ok=True)

    start_time = time.time()

    for i, (path, prompt, type_label) in enumerate(targets, 1):
        if type_label == "üêç PY":
            process_python(client, path, args.dry_run, i, total)
        else:
            process_markdown(client, path, prompt, type_label, args.dry_run, i, total)

        # Rate limiting ‚Äî solo si no es el √∫ltimo
        if i < total:
            time.sleep(DELAY_BETWEEN)

    # ‚îÄ‚îÄ‚îÄ RESUMEN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    elapsed = time.time() - start_time
    mins, secs = divmod(int(elapsed), 60)

    print(f"\n{'‚îÄ' * 52}")
    print(f"{c(BOLD, 'üìä RESULTADOS DEL ENJAMBRE')}")
    print(f"  ‚úÖ OK:      {stats['ok']}")
    print(f"  ‚è≠  Skip:    {stats['skip']}")
    print(f"  ‚ùå Fail:    {stats['fail']}")
    print(f"  ‚è±  Tiempo:  {mins}m {secs}s")
    print(f"{'‚îÄ' * 52}")

    if failures:
        print(f"\n{c(RED, '‚ùå FALLOS:')}")
        for path_str, reason in failures:
            print(f"  {path_str}: {reason}")

    log(f"SUMMARY ok={stats['ok']} skip={stats['skip']} fail={stats['fail']} time={mins}m{secs}s")
    print(f"\n{c(DIM, f'Log: {LOG_FILE}')}")
    print(f"{c(DIM, f'Backup: {BACKUP_DIR}')}\n")


if __name__ == "__main__":
    main()
