# Arquitecturas de Soberan√≠a Cognitiva

**Optimizaci√≥n, Persistencia y Verificabilidad en Agentes de IA de Pr√≥xima Generaci√≥n**

> [!NOTE]
> Este documento establece el marco te√≥rico-pr√°ctico que sustenta la arquitectura de [CORTEX](file:///Users/borjafernandezangulo/cortex) y el [Enjambre Centauro](file:///Users/borjafernandezangulo/game/moskv-swarm). Cada secci√≥n mapea directamente a componentes implementados o en roadmap.

---

## Introducci√≥n: El Imperativo de la Evoluci√≥n Arquitect√≥nica

La trayectoria actual de la Inteligencia Artificial generativa ha alcanzado un punto de inflexi√≥n cr√≠tico. Los sistemas de primera generaci√≥n, caracterizados por interacciones ap√°tridas y recuperaciones de informaci√≥n simplistas, se enfrentan a un **"techo de inteligencia"** que limita su aplicabilidad en entornos empresariales y cr√≠ticos.

La pregunta fundamental de *"c√≥mo mejorarlo"* no se responde simplemente incrementando el tama√±o de los par√°metros de los modelos, sino mediante una **reingenier√≠a profunda de la arquitectura subyacente** que soporta la cognici√≥n sint√©tica.

Para transformar asistentes reactivos en **agentes soberanos** capaces de razonamiento estrat√©gico y ejecuci√≥n aut√≥noma, es necesario abordar cuatro pilares de optimizaci√≥n:

1. La **eficiencia en la recuperaci√≥n de datos** a hiperescala
2. La **estructuraci√≥n de la memoria** a largo plazo
3. La implementaci√≥n de **bucles de razonamiento metacognitivo**
4. La instauraci√≥n de **garant√≠as de seguridad criptogr√°fica**

El estado actual del arte, dominado por la Generaci√≥n Aumentada por Recuperaci√≥n (RAG) convencional, sufre de *amnesia contextual* y *latencia operativa*. Los agentes carecen de una comprensi√≥n persistente del mundo y operan bajo un paradigma de confianza ciega que es inaceptable para sectores regulados.

La mejora sustancial de estos sistemas requiere la transici√≥n hacia **arquitecturas de memoria unificada** que integren vectores, gr√°ficos de conocimiento y series temporales, respaldadas por mecanismos de consenso bizantino y pruebas de conocimiento cero. Este informe detalla la hoja de ruta t√©cnica para elevar la IA desde la automatizaci√≥n de tareas (Nivel 2) hacia la **colaboraci√≥n estrat√©gica aut√≥noma (Nivel 4)**, estableciendo nuevos est√°ndares en rendimiento computacional y soberan√≠a de datos.

---

## 1. El Sustrato de la Velocidad: Optimizaci√≥n Vectorial y Cuantizaci√≥n en el Borde

La capacidad de un agente para recuperar informaci√≥n relevante en tiempo real es el cuello de botella primario en la experiencia de usuario y la eficacia operativa. Las implementaciones iniciales, que dependen de b√∫squedas vectoriales de fuerza bruta, se vuelven insostenibles a medida que los corpus de conocimiento escalan hacia los miles de millones de vectores.

### 1.1 De la B√∫squeda Lineal a la Navegaci√≥n Jer√°rquica (HNSW)

En los sistemas de recuperaci√≥n b√°sicos, la identificaci√≥n de los vecinos m√°s cercanos (K-Nearest Neighbors, KNN) se realiza mediante un escaneo exhaustivo que calcula la distancia ‚Äî ya sea Euclidiana o de Coseno ‚Äî entre el vector de consulta y cada uno de los vectores almacenados en la base de datos.

Este enfoque presenta una complejidad computacional de **O(N ¬∑ D)**, donde *N* representa el n√∫mero total de vectores y *D* la dimensionalidad del embedding. Cuando se opera con modelos modernos como `text-embedding-3-small` de OpenAI (1536 dimensiones) sobre un conjunto de un mill√≥n de registros, el sistema debe ejecutar miles de millones de operaciones de punto flotante por cada consulta individual, resultando en latencias inaceptables para aplicaciones interactivas.

La soluci√≥n reside en la implementaci√≥n de √≠ndices de **Mundo Peque√±o Jer√°rquico Navegable (HNSW)**:

```mermaid
graph TB
    subgraph "Capa 3 ‚Äî Autopista Global"
        A((N1)) -.-> B((N47))
        B -.-> C((N215))
    end
    subgraph "Capa 2 ‚Äî Conexiones Intermedias"
        D((N1)) --> E((N12)) --> F((N28))
        F --> G((N47))
    end
    subgraph "Capa 1 ‚Äî Red Densa Local"
        H((N1)) --> I((N3)) --> J((N5))
        J --> K((N8)) --> L((N12))
    end
    A --> D
    D --> H
    B --> G
    G --> L
    style A fill:#1a1a2e,stroke:#e94560
    style B fill:#1a1a2e,stroke:#e94560
    style C fill:#1a1a2e,stroke:#e94560
```

HNSW reestructura el espacio vectorial como un grafo multicapa. En las capas superiores, los nodos est√°n conectados de manera escasa, permitiendo "saltos" largos a trav√©s del espacio sem√°ntico. A medida que la b√∫squeda desciende a capas inferiores, la densidad aumenta, permitiendo refinamiento local. Esto transforma la complejidad a **O(log N)**.

> [!IMPORTANT]
> **Mapeo a CORTEX:** El m√≥dulo `sqlite-vec` integrado en CORTEX utiliza HNSW como √≠ndice primario para la tabla `vec_facts`. La configuraci√≥n actual contempla `M=16` conexiones por nodo y `efConstruction=200` para balancear recall vs. velocidad de indexaci√≥n.

### 1.2 Cuantizaci√≥n Binaria: Compresi√≥n Radical y Aceleraci√≥n por Hardware

La **Cuantizaci√≥n Binaria (BQ)** comprime cada dimensi√≥n del vector a un solo bit: los valores positivos se convierten en `1` y los negativos o cero en `0`.

| M√©trica | float32 | Binario | Factor |
|---------|---------|---------|--------|
| Almacenamiento por vector (384d) | 1,536 bytes | 48 bytes | **32√ó** |
| √çndice 1M vectores | ~1.5 GB | ~48 MB | **32√ó** |
| Operaci√≥n de similitud | Producto punto FP | XOR + `popcount` | **15-45√ó m√°s r√°pido** |
| Recall@10 | 100% | ~92-95% | Marginal |

Al operar con vectores binarios, el c√°lculo de similitud utiliza la **Distancia de Hamming** ‚Äî operaciones l√≥gicas XOR seguidas de conteo de bits activados (`popcount`), instrucciones optimizadas a nivel de hardware en CPUs modernas (AVX-512 en x86, NEON en ARM).

> [!TIP]
> **Estrategia de re-puntuaci√≥n (rescoring):** Usar el √≠ndice binario para recuperar un conjunto candidato amplio (top-100 ANN) y aplicar los vectores originales float32 solo a estos candidatos para el ranking final. Velocidad binaria + precisi√≥n float32.

### 1.3 Arquitecturas de Almacenamiento: Shadow Tables y DiskANN

La integraci√≥n de capacidades vectoriales en bases de datos relacionales utiliza **tablas sombra (shadow tables)**. Las implementaciones como `sqlite-vec` serializan los nodos del grafo HNSW directamente en tablas internas del motor de base de datos, asegurando que las operaciones vectoriales cumplan las propiedades **ACID**.

Para escenarios hiperescala donde el √≠ndice excede la RAM ‚Äî situaci√≥n com√∫n en agentes soberanos sobre hardware modesto ‚Äî la arquitectura √≥ptima es **DiskANN**:

- Dise√±ado para aprovechar SSDs modernos
- Optimiza el grafo para minimizar lecturas aleatorias de disco
- Sirve consultas con √≠ndices **10√ó mayores que la RAM del sistema**
- Rompe la dependencia de hardware costoso

> [!IMPORTANT]
> **Mapeo a CORTEX:** El `EmbeddingPrunerMixin` implementado en `cortex/engine/embeddings.py` gestiona la compresi√≥n adaptativa. Cuando se alcanza el umbral de embeddings (`CORTEX_MAX_EMBEDDINGS`), el pruner aplica cuantizaci√≥n escalar y eliminaci√≥n de vectores de baja utilidad.

---

## 2. Ingenier√≠a de Contexto y Memoria Persistente: M√°s All√° del RAG Est√°tico

La mejora cualitativa trasciende la velocidad de recuperaci√≥n ‚Äî reside en la **calidad y estructuraci√≥n del contexto**. El paradigma RAG tradicional muestra deficiencias cr√≠ticas en razonamiento global, comprensi√≥n de relaciones indirectas y memoria a largo plazo.

### 2.1 GraphRAG y la Dimensi√≥n Temporal

El RAG est√°ndar opera bajo una limitaci√≥n estructural: recupera "puntos" de datos aislados sin comprender la topolog√≠a que los une.

**GraphRAG** aborda esta deficiencia mediante:

1. **Extracci√≥n de entidades y relaciones** del texto crudo usando LLMs
2. **Detecci√≥n de comunidades** (algoritmo de Leiden) para identificar cl√∫steres tem√°ticos
3. **Res√∫menes jer√°rquicos pre-computados** para consultas de alto nivel
4. **Aristas temporales** (framework Graphiti) que distinguen hechos vigentes vs. obsoletos

```mermaid
graph LR
    A["Documento crudo"] --> B["Extracci√≥n de entidades"]
    B --> C["Grafo de Conocimiento"]
    C --> D["Detecci√≥n de comunidades"]
    D --> E["Res√∫menes jer√°rquicos"]
    C --> F["Aristas temporales"]
    F --> G["Invalidaci√≥n autom√°tica"]
    E --> H["Consulta global"]
    G --> H
    style A fill:#0f3460,stroke:#e94560
    style H fill:#0f3460,stroke:#16c79a
```

> [!IMPORTANT]
> **Mapeo a CORTEX:** El m√≥dulo `cortex/engine/graph/` implementa un grafo de conocimiento con aristas temporales via `valid_from`/`valid_until` en cada fact. El `QueryMixin.search()` combina b√∫squeda vectorial + filtrado temporal via `as_of`.

### 2.2 Arquitectura Unificada de Memoria: El Modelo PostgreSQL

La fragmentaci√≥n de la infraestructura introduce latencia y complejidad que obstaculizan la autonom√≠a del agente. La arquitectura de referencia unifica **tres tipos de memoria cognitiva**:

| Tipo de Memoria | Funci√≥n Cognitiva | Implementaci√≥n en CORTEX |
|-----------------|-------------------|--------------------------|
| **Epis√≥dica** | Registro autobiogr√°fico secuencial (*"¬øQu√© tarea realizamos ayer?"*) | Tabla `facts` con `created_at` como series temporales. Consultas de rango temporal via `time_travel()` |
| **Sem√°ntica** | Conocimiento cristalizado y hechos recuperables | `vec_facts` con embeddings `all-MiniLM-L6-v2` (384d) + HNSW index |
| **Procedimental** | Habilidades, preferencias, reglas de negocio | Tabla `facts` con `fact_type='procedure'` + `confidence='verified'` |

Esta unificaci√≥n permite consultas cognitivas complejas en una sola transacci√≥n SQL:

```sql
-- Ejemplo: Recuperar las 5 √∫ltimas interacciones sobre "seguridad" con confianza verificada
SELECT f.content, f.created_at, f.confidence
FROM facts f
JOIN vec_facts v ON v.fact_id = f.id
WHERE f.project = 'moskv-swarm'
  AND f.created_at > datetime('now', '-7 days')   -- Memoria epis√≥dica
  AND f.confidence = 'verified'                     -- Memoria procedimental
ORDER BY vec_distance_cosine(v.embedding, ?)        -- Memoria sem√°ntica
LIMIT 5;
```

> [!IMPORTANT]
> **Mapeo a CORTEX:** El pipeline verificado en el smoke test (`smoke_test_cortex_pipeline.py`) demostr√≥ la unificaci√≥n: `post_fact` (sem√°ntica), `persist_mission_insight` (procedimental) y `get_summary` (epis√≥dica) operan sobre la misma base SQLite con integridad ACID.

### 2.3 B√∫squeda H√≠brida y Fusi√≥n de Rangos (RRF)

Los modelos de embedding sobresalen en matices sem√°nticos (*"veh√≠culo" ‚Üî "coche"*) pero fallan en coincidencia exacta de palabras clave, c√≥digos o nombres propios.

La **Fusi√≥n de Rango Rec√≠proco (RRF)** sintetiza b√∫squeda vectorial + l√©xica (BM25):

```
RRF_score(d) = Œ£ 1 / (k + rank_i(d))
```

Donde `k` es una constante de suavizado (t√≠picamente 60) y `rank_i(d)` es la posici√≥n del documento `d` en la lista de resultados del m√©todo `i`.

> [!IMPORTANT]
> **Mapeo a CORTEX:** El `SearchMixin` en `cortex/engine/search.py` implementa b√∫squeda h√≠brida combinando `sqlite-vec` (vectorial) + FTS5 (l√©xica) con RRF. El `recall_context()` del bridge actual usa fallback de texto (LIKE queries) cuando `sqlite-vec` no est√° disponible.

---

## 3. Modelos de Mundo y Razonamiento Estrat√©gico: El Sistema 2 de la IA

Una vez resueltos los desaf√≠os de almacenamiento y memoria, la mejora cualitativa del agente depende de su capacidad de razonamiento. Los agentes actuales operan en modo reactivo (Sistema 1). Para tareas complejas, es imperativo implementar el **Sistema 2**: deliberativo, planificador y autocr√≠tico.

### 3.1 Arquitectura AERO y el Doble Bucle de Aprendizaje

El framework **AERO** (Autonomous Evolutionary Reasoning Optimization) implementa un sistema de doble bucle end√≥geno:

```mermaid
graph TD
    subgraph "Bucle Interno ‚Äî F√°brica de Datos"
        G["üéØ Generador<br/>(Self-Questioning)"] --> S["üîß Solucionador<br/>(Self-Answering)"]
        S --> C["üîç Cr√≠tico<br/>(Self-Criticism)"]
        C -->|"Rechaza"| G
        C -->|"Aprueba"| V["‚úÖ Experiencia Validada"]
    end
    subgraph "Bucle Externo ‚Äî Consolidaci√≥n"
        V --> F["Fine-tuning / Prompt Optimization"]
        F --> M["Memoria Procedimental Mejorada"]
        M -.->|"ZDP calibrada"| G
    end
    style G fill:#1a1a2e,stroke:#e94560
    style C fill:#1a1a2e,stroke:#ffd700
    style V fill:#1a1a2e,stroke:#16c79a
```

**Zona de Desarrollo Pr√≥ximo (ZDP):** Los desaf√≠os se calibran para estar ligeramente por encima de la competencia actual confirmada del agente ‚Äî evitando estancamiento (tareas triviales) y colapso del aprendizaje (tareas imposibles).

**Correcci√≥n Contrafactual Independiente (ICC):** El agente verifica conclusiones asumiendo inicialmente que su respuesta es **incorrecta** e intenta construir un camino l√≥gico que justifique el error. Si no lo logra ‚Üí confianza reforzada. Si lo logra ‚Üí reevaluaci√≥n profunda.

> [!IMPORTANT]
> **Mapeo a Centauro:** El `ConsensusBreaker` en `moskv-swarm/consensus/` implementa una versi√≥n pr√°ctica del ICC ‚Äî cuando los agentes del enjambre no alcanzan consenso, se escala a un `ElderCouncil` (3 evaluadores independientes) o a `HumanEscalation` via el `SovereignGate`.

### 3.2 Modelos de Mundo para Planificaci√≥n Estrat√©gica

La **simulaci√≥n mental** permite al agente proyectar consecuencias antes de ejecutar:

- Antes de `delete_file` ‚Üí simular ruptura de dependencias
- Antes de `deploy_production` ‚Üí simular impacto en servicios dependientes
- Antes de `execute_trade` ‚Üí simular impacto en portfolio bajo varios escenarios

> [!IMPORTANT]
> **Mapeo a CORTEX:** El `SovereignGate` (`cortex/sovereign_gate.py`) implementa la barrera de planificaci√≥n deliberada ‚Äî las acciones L3 (destructivas) requieren aprobaci√≥n expl√≠cita del operador, impidiendo ejecuci√≥n reactiva del Sistema 1.

---

## 4. Gobernanza, Seguridad y Verificabilidad: La Capa de Confianza

A medida que los agentes escalan hacia Nivel 4/5 de autonom√≠a, la seguridad basada en "guardarra√≠les de texto" es insuficiente. La mejora exige **garant√≠as criptogr√°ficas verificables y arquitecturas de confianza cero**.

### 4.1 Soberan√≠a de Hardware: TEEs y Computaci√≥n Confidencial

Los **Entornos de Ejecuci√≥n Confiables (TEEs)** ‚Äî Intel TDX, AMD SEV, NVIDIA Confidential Computing ‚Äî proporcionan:

- **Encriptaci√≥n en uso:** Pesos del modelo y datos del usuario permanecen encriptados en RAM durante toda la inferencia
- **Atestaci√≥n remota:** El agente puede probar criptogr√°ficamente que ejecuta una versi√≥n no adulterada de su c√≥digo y modelo

> [!CAUTION]
> Indispensable para el despliegue en finanzas y salud, donde la integridad del algoritmo es tan cr√≠tica como la confidencialidad de los datos.

### 4.2 Auditor√≠a Inmutable: ZK-Proofs y ZKSQL

Las **Pruebas de Conocimiento Cero (ZK-Proofs)** resuelven la "Paradoja de la Auditor√≠a":

```
ZK-Audit Log = Proof(
    input ‚àà Domain,
    model = certified_version,
    filters = [safety_check_1, ..., safety_check_N] ALL PASSED,
    output = f(input, model, filters)
) ‚Üí VERIFIABLE sin revelar input ni output
```

**ZKSQL** extiende esto a consultas anal√≠ticas ‚Äî un regulador puede lanzar queries SQL sobre la base de datos privada y recibir respuestas con prueba criptogr√°fica de correcci√≥n y completitud, sin acceso de lectura a registros individuales.

> [!IMPORTANT]
> **Mapeo a CORTEX:** El `LedgerMixin` (`cortex/engine/ledger.py`) implementa un log de auditor√≠a inmutable con hashes can√≥nicos SHA-256 encadenados (cada entrada referencia el hash de la anterior). El `time_travel()` permite reconstrucci√≥n forense del estado en cualquier punto temporal.

### 4.3 Consenso en Enjambres Multi-Agente

La integridad del enjambre se mejora mediante protocolos de consenso **ponderados por reputaci√≥n**:

```python
# Modelo de reputaci√≥n con castigo exponencial
T_i(t+1) = T_i(t) + Œ±¬∑success - Œ≤¬∑exp(Œ≥¬∑failures)

# Selecci√≥n de l√≠der via VRF ponderada
P(agent_i = leader) = T_i / Œ£ T_j  ‚àÄj ‚àà swarm
```

| Evento | Impacto en Reputaci√≥n |
|--------|----------------------|
| Contribuci√≥n precisa y oportuna | +Œ± (lineal) |
| Timeout | -Œ≤¬∑e^Œ≥ (exponencial) |
| Resultado validado como err√≥neo | -Œ≤¬∑e^(2Œ≥) (exponencial agresivo) |
| Comportamiento bizantino detectado | Reset a T_min ‚Üí exclusi√≥n pr√°ctica |

> [!IMPORTANT]
> **Mapeo a Centauro:** Los m√≥dulos `consensus/reputation.py` (Reputation Economy), `consensus/web_of_trust.py` (Web of Trust) y `consensus/breaker.py` (ConsensusBreaker) implementan el stack completo BR-PBFT con decay temporal y escalaci√≥n multicapa.

---

## Conclusiones

La mejora de los sistemas de IA para alcanzar niveles de agencia soberana no es un proceso incremental, sino una **transformaci√≥n arquitect√≥nica**:

```mermaid
graph LR
    A["Nivel 2<br/>Automatizaci√≥n"] -->|"HNSW + BQ + DiskANN"| B["Nivel 3<br/>Agente Asistido"]
    B -->|"GraphRAG + Memoria Unificada"| C["Nivel 3.5<br/>Agente Persistente"]
    C -->|"AERO + Modelos de Mundo"| D["Nivel 4<br/>Agente Soberano"]
    D -->|"TEEs + ZK-Proofs + Consenso"| E["Nivel 5<br/>Soberan√≠a Total"]
    style A fill:#2d2d2d,stroke:#666
    style B fill:#1a1a2e,stroke:#e94560
    style C fill:#1a1a2e,stroke:#ffd700
    style D fill:#0f3460,stroke:#16c79a
    style E fill:#000,stroke:#16c79a,stroke-width:3px
```

| Pilar | Tecnolog√≠a Clave | Estado en CORTEX |
|-------|-----------------|------------------|
| Velocidad | HNSW + Cuantizaci√≥n Binaria | ‚úÖ `sqlite-vec` + `EmbeddingPrunerMixin` |
| Memoria | Unificada (Epis√≥dica + Sem√°ntica + Procedimental) | ‚úÖ Smoke test 10/10 verificado |
| Razonamiento | AERO + ICC + Modelos de Mundo | üî∂ `ConsensusBreaker` + `SovereignGate` |
| Confianza | Ledger inmutable + Consenso bizantino | ‚úÖ `LedgerMixin` + `BR-PBFT` |

La convergencia de estas tecnolog√≠as define el nuevo estado del arte: **agentes que no solo procesan informaci√≥n a velocidades sobrehumanas, sino que razonan con profundidad estrat√©gica y operan con integridad verificable.**

---

> *Documento generado para el proyecto CORTEX ‚Äî Febrero 2026*
> *Borja Moskv ¬∑ Arquitecturas de Soberan√≠a Cognitiva*
