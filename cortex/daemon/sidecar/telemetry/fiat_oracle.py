"""
CORTEX v6 ‚Äî Fiat Oracle Sidecar (Operation Citadel).
Monitors financial transactions (Simulated/Bunq) and pushes facts to the ledger.
Sovereign Standard (130/100): Zero-Trust inputs, Backoff, Persistent Queues, Idempotency.
"""

import asyncio
import hashlib
import json
import logging
import random
import time
from pathlib import Path
from typing import Any, Final

from cortex.errors import CortexError

logger = logging.getLogger(__name__)

# --- Sovereign Constants ---
MAX_RETRIES: Final[int] = 3
BASE_BACKOFF: Final[float] = 1.1


class FiatOracle:
    """Monitors fiat flow and emits telemetry events. (Zero-Trust)"""

    def __init__(self, engine: Any, interval: float = 30.0):
        # We accept both sync and async engine for flexibility
        self.engine = engine
        self.interval = interval
        self.running = False
        
        # Operation Citadel: Persistent Queue approach (No Single File Spoilage)
        self.queue_dir = Path("~/.cortex/fiat_queue").expanduser()
        self.queue_dir.mkdir(parents=True, exist_ok=True)
        
        self.processed_txs: set[str] = set() # Ephemeral Idempotency memory

    async def run_loop(self):
        """Main async loop for the sidecar."""
        self.running = True
        logger.info("üí∏ [FIAT_ORACLE] Activated. Monitoring sovereign capital flow (DEFCON 1).")
        
        while self.running:
            try:
                await self._check_signals()
            except Exception as e:
                logger.error(f"‚ùå [FIAT_ORACLE] Error: {e}")
            await asyncio.sleep(self.interval)

    def run_sync_loop(self):
        """For running in MoskvDaemon separate thread."""
        logger.info("üí∏ [FIAT_ORACLE] (Thread) started.")
        self.running = True
        while self.running:
            try:
                # We use sync checks here if called from a thread
                self._check_signals_sync()
            except Exception as e:
                logger.error(f"‚ùå [FIAT_ORACLE] (Thread) Error: {e}")
            time.sleep(self.interval)

    def _verify_signature(self, data: dict, signature: str) -> bool:
        """
        Anti-Spoofing: Verifies that the payload was generated by a trusted source.
        Uses a dummy SOVEREIGN_KEY_MOCK for architectural simulation.
        """
        if not signature:
            return False
            
        # Reconstruct payload to compute hash (excluding the signature itself)
        # Note: In real life we'd use hmac and a real env variable.
        payload_copy = {k: v for k, v in data.items() if k != "signature"}
        payload_str = json.dumps(payload_copy)
        
        expected_hash = hashlib.sha256((payload_str + "SOVEREIGN_KEY_MOCK").encode()).hexdigest()
        return signature == expected_hash

    async def _check_signals(self):
        """Check for simulated transactions in the persistent queue."""
        for tx_file in self.queue_dir.glob("*.json"):
            try:
                content = tx_file.read_text()
                data = json.loads(content)
                
                # 1. Zero-Trust Validation
                signature = data.get("signature")
                if not self._verify_signature(data, signature):
                    logger.critical(f"üö® [FIAT_ORACLE] Firma inv√°lida rechazada. Posible Spoofing: {tx_file.name}")
                    tx_file.unlink() # Delete malicious file immediately
                    continue
                
                # 2. Idempotency Check
                tx_id = data.get("tx_id")
                if tx_id in self.processed_txs:
                    logger.warning(f"üõ°Ô∏è [FIAT_ORACLE] Prevented replay attack para TX: {tx_id}")
                    tx_file.unlink()
                    continue

                # 3. Process & Commit
                await self._process_transaction(data)
                
                # 4. Finalize
                self.processed_txs.add(tx_id)
                tx_file.unlink() # Cleanup only after successful commit

            except json.JSONDecodeError:
                logger.error(f"‚ùå [FIAT_ORACLE] Payload corrupto en {tx_file.name}")
                tx_file.unlink()
            except Exception as e:
                logger.error(f"‚ö†Ô∏è [FIAT_ORACLE] Falla procesando {tx_file.name}: {e}")

    def _check_signals_sync(self):
        """Sync version for threaded execution."""
        for tx_file in self.queue_dir.glob("*.json"):
            try:
                content = tx_file.read_text()
                data = json.loads(content)
                
                # 1. Zero-Trust Validation
                signature = data.get("signature")
                if not self._verify_signature(data, signature):
                    logger.critical(f"üö® [FIAT_ORACLE] Firma inv√°lida rechazada. Posible Spoofing: {tx_file.name}")
                    tx_file.unlink()
                    continue

                # 2. Idempotency Check
                tx_id = data.get("tx_id")
                if tx_id in self.processed_txs:
                    logger.warning(f"üõ°Ô∏è [FIAT_ORACLE] Prevented replay attack para TX: {tx_id}")
                    tx_file.unlink()
                    continue

                # 3. Process & Commit
                self._process_transaction_sync(data)
                
                # 4. Finalize
                self.processed_txs.add(tx_id)
                tx_file.unlink()

            except json.JSONDecodeError:
                logger.error(f"‚ùå [FIAT_ORACLE] Payload corrupto en {tx_file.name}")
                tx_file.unlink()
            except Exception as e:
                logger.error(f"‚ö†Ô∏è [FIAT_ORACLE] Falla procesando {tx_file.name}: {e}")

    async def _execute_with_backoff(self, payload: dict[str, Any], is_sync: bool = False):
        """Resilient storage with exponential backoff avoiding 'Database is locked' errors."""
        amount = payload.get("amount", "0")
        currency = payload.get("currency", "EUR")
        source = payload.get("source", "BUNQ_REDIRECT")
        tx_id = payload.get("tx_id", "UNKNOWN")
        
        logger.info(f"üí∞ [FIAT_STREAM] Detected {amount} {currency} from {source} [TX:{tx_id}]")
        
        meta = {
            "oracle": "fiat_oracle_v1.3.0",
            "amount": amount,
            "currency": currency,
            "provider": "bunq",
            "tx_id": tx_id
        }

        last_error = None
        for attempt in range(MAX_RETRIES):
            try:
                if is_sync:
                    if hasattr(self.engine, "store"):
                        self.engine.store(
                            project="cortex-revenue",
                            content=f"Received {amount} {currency} via {source}",
                            fact_type="fiat_transaction",
                            meta=meta
                        )
                else:
                    if hasattr(self.engine, "store"):
                        await self.engine.store(
                            project="cortex-revenue",
                            content=f"Received {amount} {currency} via {source}",
                            fact_type="fiat_transaction",
                            meta=meta
                        )
                return # Exito
            
            except Exception as e:
                last_error = e
                delay = (BASE_BACKOFF**attempt) + (random.random() * 0.1)
                logger.error(f"‚öôÔ∏è [FIAT_ORACLE] DB lock o error: {e}. Reintento {attempt+1}/{MAX_RETRIES} en {delay:.2f}s")
                if is_sync:
                    time.sleep(delay)
                else:
                    await asyncio.sleep(delay)
                    
        logger.critical(f"üíÄ [FIAT_ORACLE] Falla catastr√≥fica almacenando TX {tx_id} tras {MAX_RETRIES} intentos.")
        raise CortexError(f"FiatOracle DB Failure: {last_error}") from last_error

    async def _process_transaction(self, data: dict):
        """Store transaction in ledger (Async)."""
        await self._execute_with_backoff(data, is_sync=False)

    def _process_transaction_sync(self, data: dict):
        """Store transaction in ledger (Sync)."""
        # Wrapping the async method structure, we use the is_sync flag
        import threading
        
        # Un peque√±o hack para usar el backoff sin await en entorno s√≠ncrono.
        # Alternativamente podr√≠amos desplegar un subloop, pero dado que 
        # MoskvDaemon corre sidecars en un hilo...
        
        # Como _execute_with_backoff es async, en la versi√≥n s√≠ncrona 
        # lo reconstruimos localmente o invocamos un event loop temporal.
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # Estamos en un thread que ya tiene loop corriendo
                 asyncio.run_coroutine_threadsafe(self._execute_with_backoff(data, is_sync=False), loop).result()
            else:
                loop.run_until_complete(self._execute_with_backoff(data, is_sync=False))
        except RuntimeError:
            # No hay loop en este thread
            asyncio.run(self._execute_with_backoff(data, is_sync=False))

    def stop(self):
        self.running = False
