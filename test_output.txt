============================= test session starts ==============================
platform darwin -- Python 3.14.3, pytest-9.0.2, pluggy-1.6.0 -- /Users/borjafernandezangulo/cortex/.venv/bin/python3.14
cachedir: .pytest_cache
rootdir: /Users/borjafernandezangulo/cortex
configfile: pyproject.toml
plugins: anyio-4.12.1, asyncio-1.3.0, cov-7.0.0
asyncio: mode=Mode.AUTO, debug=False, asyncio_default_fixture_loop_scope=function, asyncio_default_test_loop_scope=function
collecting ... collected 3 items

tests/test_consensus.py::test_consensus_flow Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]Loading weights:   1%|          | 1/103 [00:00<00:00, 1358.70it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   1%|          | 1/103 [00:00<00:00, 1117.29it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   2%|â–         | 2/103 [00:00<00:00, 368.60it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   2%|â–         | 2/103 [00:00<00:00, 352.42it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 354.48it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 350.18it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   4%|â–         | 4/103 [00:00<00:00, 449.08it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   4%|â–         | 4/103 [00:00<00:00, 446.27it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   5%|â–         | 5/103 [00:00<00:00, 553.15it/s, Materializing param=embeddings.word_embeddings.weight]      Loading weights:   5%|â–         | 5/103 [00:00<00:00, 551.20it/s, Materializing param=embeddings.word_embeddings.weight]Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 656.23it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 652.52it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 753.58it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 748.98it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 847.46it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 845.22it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 944.88it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 941.72it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1039.07it/s, Materializing param=encoder.layer.0.attention.self.key.bias]    Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1036.07it/s, Materializing param=encoder.layer.0.attention.self.key.bias]Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1133.32it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1130.29it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1227.36it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1224.50it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1315.65it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1312.46it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1405.63it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1402.24it/s, Materializing param=encoder.layer.0.attention.self.value.bias]Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 1494.94it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 1486.32it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 1578.70it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 1575.10it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 1664.25it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 1660.49it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 1749.61it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 1745.85it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1834.53it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1829.89it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 1918.45it/s, Materializing param=encoder.layer.0.output.dense.bias]      Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 1914.42it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 2002.87it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 1962.23it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 2005.62it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 1852.31it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 1664.98it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 1653.00it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 1697.55it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 1677.61it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1725.45it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1710.45it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 1740.32it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 1717.30it/s, Materializing param=encoder.layer.1.attention.self.key.bias]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 1751.90it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 1736.11it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 1781.07it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 1770.02it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 1787.59it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 1769.36it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 1805.81it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 1793.61it/s, Materializing param=encoder.layer.1.attention.self.value.bias]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 1835.50it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 1824.17it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 1866.65it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 1809.35it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 1812.70it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 1797.19it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 1831.50it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 1820.51it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 1611.49it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 1524.73it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 1522.46it/s, Materializing param=encoder.layer.1.output.dense.bias]      Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 1518.09it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 1548.38it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 1545.22it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 1583.13it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 1580.64it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 1618.25it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 1616.53it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 1642.38it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 1632.72it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 1657.51it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 1649.18it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 1678.39it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 1673.31it/s, Materializing param=encoder.layer.2.attention.self.key.bias]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 1699.20it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 1683.56it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 1712.53it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 1701.81it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 1720.97it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 1718.54it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 1749.05it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 1746.93it/s, Materializing param=encoder.layer.2.attention.self.value.bias]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 1779.28it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 1777.47it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 1798.70it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 1792.33it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 1808.80it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 1802.14it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 1820.30it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 1812.19it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 1821.50it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 1816.50it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 1835.32it/s, Materializing param=encoder.layer.2.output.dense.bias]      Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 1823.67it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 1839.20it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 1824.00it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 1842.38it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 1833.86it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 1837.82it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 1825.18it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 1843.87it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 1836.00it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 1856.98it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 1851.86it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 1872.83it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 1869.64it/s, Materializing param=encoder.layer.3.attention.self.key.bias]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 1888.84it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 1883.00it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 1901.80it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 1895.97it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 1916.01it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 1905.72it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1922.06it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 1911.93it/s, Materializing param=encoder.layer.3.attention.self.value.bias]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1932.87it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 1930.80it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1955.22it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 1953.59it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 1963.16it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 1960.73it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1987.29it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 1981.33it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 2004.91it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 2003.22it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 2030.58it/s, Materializing param=encoder.layer.3.output.dense.bias]      Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 2029.07it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 2056.02it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 2054.48it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 2081.66it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 2080.18it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 2106.45it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 2104.89it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 2132.00it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 2129.85it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 2156.06it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 2154.60it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 2181.54it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 2179.43it/s, Materializing param=encoder.layer.4.attention.self.key.bias]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 2204.85it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 2203.09it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 2229.53it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 2227.96it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 2254.44it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 2252.85it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 2279.43it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 2277.91it/s, Materializing param=encoder.layer.4.attention.self.value.bias]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 2304.27it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 2302.74it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 2328.89it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 2327.41it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 2352.19it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 2350.61it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 2377.02it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 2375.51it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 2401.47it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 2399.80it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 2426.14it/s, Materializing param=encoder.layer.4.output.dense.bias]      Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 2424.52it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 2450.70it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 2449.22it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 2463.55it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 2450.98it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 2456.03it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 2448.09it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 2459.97it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 2419.70it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 2421.90it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 2418.61it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 2441.01it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 2439.08it/s, Materializing param=encoder.layer.5.attention.self.key.bias]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 2462.86it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 2451.90it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 2444.47it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 2433.73it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 2439.68it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 2428.39it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 2442.39it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 2437.51it/s, Materializing param=encoder.layer.5.attention.self.value.bias]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 2455.35it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 2450.98it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 2467.04it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 2460.27it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 2475.06it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 2470.07it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 2487.38it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 2483.79it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 2499.56it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 2496.16it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 2513.89it/s, Materializing param=encoder.layer.5.output.dense.bias]     Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 2511.50it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 2531.97it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 2529.75it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 2551.65it/s, Materializing param=pooler.dense.bias]                  Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 2550.00it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 2570.90it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 2569.41it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 2563.71it/s, Materializing param=pooler.dense.weight]
[1mBertModel LOAD REPORT[0m from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
FAILED
tests/test_consensus.py::test_recall_ordering FAILED
tests/test_consensus.py::test_rwc_flow FAILED

=================================== FAILURES ===================================
_____________________________ test_consensus_flow ______________________________

client = <starlette.testclient.TestClient object at 0x10ba98590>

    def test_consensus_flow(client):
        """Test standard consensus flow (upvote/downvote)."""
        # 1. Register agent
        resp = client.post("/v1/agents", json={"name": "test-agent", "agent_type": "ai"})
        if resp.status_code != 200:
            print(f"Register Failed: {resp.text}")
        assert resp.status_code == 200
        agent_id = resp.json()["agent_id"]
    
        # 2. Store fact
        resp = client.post("/v1/facts", json={"project": "test_proj", "content": "The Earth is round"})
        if resp.status_code != 200:
            print(f"Store Failed: {resp.text}")
        assert resp.status_code == 200
        fact_id = resp.json()["fact_id"]
    
        # 3. Upvote
        resp = client.post(f"/v1/facts/{fact_id}/vote", json={"agent_id": agent_id, "vote": 1})
>       assert resp.status_code == 200
E       assert 422 == 200
E        +  where 422 = <Response [422 Unprocessable Entity]>.status_code

tests/test_consensus.py:73: AssertionError
------------------------------ Captured log call -------------------------------
WARNING  huggingface_hub.utils._http:_http.py:779 Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
_____________________________ test_recall_ordering _____________________________

client = <starlette.testclient.TestClient object at 0x10b9a3ed0>

    def test_recall_ordering(client):
        """Test standard recall ordering (score + recency)."""
        from cortex import api_state
        engine = api_state.engine
    
        # 1. Store 3 facts
        engine.store_sync("test_proj", "Fact A")
        engine.store_sync("test_proj", "Fact B")
        fid_c = engine.store_sync("test_proj", "Fact C")
    
        # 2. Add some votes to Fact C (Upvote)
        resp = client.post("/v1/agents", json={"name": "vote-agent", "agent_type": "ai"})
        agent_id = resp.json()["agent_id"]
    
        client.post(f"/v1/facts/{fid_c}/vote", json={"agent_id": agent_id, "vote": 1})
    
        # 3. Recall and check order (Fact C should be first)
        resp = client.get("/v1/recall?project=test_proj")
        facts = resp.json()
>       assert facts[0]["content"] == "Fact C"
               ^^^^^^^^
E       KeyError: 0

tests/test_consensus.py:101: KeyError
________________________________ test_rwc_flow _________________________________

client = <starlette.testclient.TestClient object at 0x1094c1bd0>

    def test_rwc_flow(client):
        """Test Reputation-Weighted Consensus flow."""
        from cortex import api_state
        engine = api_state.engine
    
        # 1. Register 2 agents
        resp1 = client.post("/v1/agents", json={"name": "whale", "agent_type": "ai"})
        agent_whale = resp1.json()["agent_id"]
    
        resp2 = client.post("/v1/agents", json={"name": "shrimp", "agent_type": "ai"})
        agent_shrimp = resp2.json()["agent_id"]
    
        # 2. Boost reputation in DB
        conn = engine._get_sync_conn()
        conn.execute("UPDATE agents SET reputation_score = 10.0 WHERE id = ?", (agent_whale,))
        conn.execute("UPDATE agents SET reputation_score = 1.0 WHERE id = ?", (agent_shrimp,))
        conn.commit()
    
        # 3. Store a fact
        fid = engine.store_sync("test_proj", "Reputation Test Fact")
    
        # 4. Shrimp downvotes (-1), Whale upvotes (+1)
        client.post(f"/v1/facts/{fid}/vote", json={"agent_id": agent_shrimp, "vote": -1})
        client.post(f"/v1/facts/{fid}/vote", json={"agent_id": agent_whale, "vote": 1})
    
        # 5. Check score (should be > 1.0 because whale has more weight)
        resp_recall = client.get("/v1/recall?project=test_proj")
>       fact = next(f for f in resp_recall.json() if f["fact_id"] == fid)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/test_consensus.py:131: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

.0 = <dict_keyiterator object at 0x11c991b20>

>   fact = next(f for f in resp_recall.json() if f["fact_id"] == fid)
                                                 ^^^^^^^^^^^^
E   TypeError: string indices must be integers, not 'str'

tests/test_consensus.py:131: TypeError
=========================== short test summary info ============================
FAILED tests/test_consensus.py::test_consensus_flow - assert 422 == 200
FAILED tests/test_consensus.py::test_recall_ordering - KeyError: 0
FAILED tests/test_consensus.py::test_rwc_flow - TypeError: string indices mus...
============================== 3 failed in 23.50s ==============================
